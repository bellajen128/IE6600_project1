{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "path = \"/Users/bella/Desktop/project1\"\n",
    "\n",
    "# Load the dataset into a DataFrame\n",
    "df = pd.read_csv(f\"{path}/sentimentdataset.csv\") \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date preprocessing - categorize sentiment into \"positive\", \"neutral\", \"negative\"\n",
    "# build a emotions dictionary by chatGPT\n",
    "\n",
    "emotions_dict = {\n",
    "    \"Positive\": [\n",
    "        \"Positive\", \"Happiness\", \"Joy\", \"Love\", \"Amusement\", \"Enjoyment\", \"Admiration\", \"Affection\", \n",
    "        \"Awe\", \"Surprise\", \"Acceptance\", \"Adoration\", \"Anticipation\", \"Calmness\", \"Excitement\", \n",
    "        \"Kind\", \"Pride\", \"Elation\", \"Euphoria\", \"Contentment\", \"Serenity\", \"Gratitude\", \"Hope\", \n",
    "        \"Empowerment\", \"Compassion\", \"Tenderness\", \"Arousal\", \"Enthusiasm\", \"Fulfillment\", \n",
    "        \"Reverence\", \"Hopeful\", \"Proud\", \"Grateful\", \"Empathetic\", \"Compassionate\", \"Playful\", \n",
    "        \"Free-spirited\", \"Inspired\", \"Confident\", \"Thrill\", \"Overjoyed\", \"Inspiration\", \"Motivation\", \n",
    "        \"JoyfulReunion\", \"Satisfaction\", \"Blessed\", \"Appreciation\", \"Confidence\", \"Accomplishment\", \n",
    "        \"Wonderment\", \"Optimism\", \"Enchantment\", \"Intrigue\", \"PlayfulJoy\", \"Mindfulness\", \n",
    "        \"DreamChaser\", \"Elegance\", \"Whimsy\", \"Harmony\", \"Creativity\", \"Radiance\", \"Wonder\", \n",
    "        \"Rejuvenation\", \"Coziness\", \"Adventure\", \"Melodic\", \"FestiveJoy\", \"InnerJourney\", \"Freedom\", \n",
    "        \"Dazzle\", \"Adrenaline\", \"ArtisticBurst\", \"CulinaryOdyssey\", \"Resilience\", \"Immersion\", \n",
    "        \"Spark\", \"Marvel\", \"Positivity\", \"Kindness\", \"Friendship\", \"Success\", \"Exploration\", \n",
    "        \"Amazement\", \"Romance\", \"Captivation\", \"Tranquility\", \"Grandeur\", \"Energy\", \"Celebration\", \n",
    "        \"Charm\", \"Ecstasy\", \"Colorful\", \"Connection\", \"Journey\", \"Engagement\", \"Touched\", \"Triumph\", \n",
    "        \"Heartwarming\", \"Solace\", \"Breakthrough\", \"Joy in Baking\", \"Imagination\", \"Vibrancy\", \n",
    "        \"Mesmerizing\", \"Culinary Adventure\", \"Winter Magic\", \"Thrilling Journey\", \"Nature's Beauty\", \n",
    "        \"Celestial Wonder\", \"Creative Inspiration\", \"Runway Creativity\", \"Ocean's Freedom\", \n",
    "        \"Whispers of the Past\", \"Relief\", \"Happy\"\n",
    "    ],\n",
    "    \"Neutral\": [\n",
    "        \"Neutral\", \"Calmness\", \"Curiosity\", \"Indifference\", \"Numbness\", \"Melancholy\", \"Nostalgia\", \n",
    "        \"Ambivalence\", \"Determination\", \"Zest\", \"Reflection\", \"Contemplation\", \"Pensive\", \n",
    "        \"Mindfulness\", \"Elegance\", \"Harmony\", \"Tranquility\", \"Serenity\", \"Coziness\", \"Positivity\", \n",
    "        \"Contentment\", \"Exploration\", \"Journey\", \"InnerJourney\", \"Renewed Effort\", \"Solace\", \n",
    "        \"Imagination\", \"Vibrancy\", \"ArtisticBurst\", \"Intrigue\", \"Engagement\", \"Mindfulness\", \n",
    "        \"Connection\", \"Energy\", \"Harmony\", \"Journey\", \"Adventure\", \"Tranquility\", \"Playful\", \n",
    "        \"Friendship\", \"Kindness\", \"Curiosity\", \"Intrigue\", \"Serenity\"\n",
    "    ],\n",
    "    \"Negative\": [\n",
    "        \"Negative\", \"Anger\", \"Fear\", \"Sadness\", \"Disgust\", \"Disappointed\", \"Bitter\", \"Confusion\", \n",
    "        \"Shame\", \"Despair\", \"Grief\", \"Loneliness\", \"Jealousy\", \"Resentment\", \"Frustration\", \n",
    "        \"Boredom\", \"Anxiety\", \"Intimidation\", \"Helplessness\", \"Envy\", \"Regret\", \"Fearful\", \n",
    "        \"Apprehensive\", \"Overwhelmed\", \"Jealous\", \"Devastated\", \"Frustrated\", \"Envious\", \n",
    "        \"Dismissive\", \"Bitterness\", \"Desperation\", \"Isolation\", \"EmotionalStorm\", \"Darkness\", \n",
    "        \"Desolation\", \"Loss\", \"Heartache\", \"Suffering\", \"Heartbreak\", \"Betrayal\", \"Sad\", \"Hate\", \n",
    "        \"Bad\", \"Melancholy\", \"Desperation\", \"Grief\", \"Exhaustion\", \"Sorrow\", \"Desolation\", \n",
    "        \"Solitude\", \"Betrayal\", \"Miscalculation\", \"Obstacle\", \"Pressure\", \"Embarrassed\", \n",
    "        \"Heartache\", \"LostLove\", \"Suffering\", \"Boredom\", \"Anxiety\", \"Regret\", \"Numbness\", \n",
    "        \"Isolation\", \"Sadness\", \"Disappointment\", \"Despair\", \"EmotionalStorm\", \"Loneliness\", \n",
    "        \"Ruins\", \"Desolation\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# print(emotions_dict)\n",
    "\n",
    "\n",
    "# Convert the dictionary to a mapping (key-value) structure\n",
    "emotion_mapping = {}\n",
    "for key, values in emotions_dict.items():\n",
    "    for value in values:\n",
    "        emotion_mapping[value] = key\n",
    "\n",
    "\n",
    "# Clean the 'Sentiment' column to standardize the values \n",
    "# .str.strip() to remove any leading or trailing spaces\n",
    "# .title() to convert the values to title case\n",
    "df['Sentiment_clean'] = df['Sentiment'].str.strip().str.title()\n",
    "\n",
    "# Directly map the cleaned 'Sentiment' values to their categories using the emotion_mapping dictionary\n",
    "df['Emotions'] = df['Sentiment_clean'].map(emotion_mapping).fillna('Unknown')\n",
    "\n",
    "# # Display rows where 'Emotions' column has 'Unknown' values\n",
    "# unknown_rows = df[df['Emotions'] == 'Unknown']\n",
    "# print(unknown_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Text  \\\n",
      "0   Enjoying a beautiful day at the park!        ...   \n",
      "1   Traffic was terrible this morning.           ...   \n",
      "2   Just finished an amazing workout! ðŸ’ª          ...   \n",
      "3   Excited about the upcoming weekend getaway!  ...   \n",
      "4   Trying out a new recipe for dinner tonight.  ...   \n",
      "\n",
      "                                            text_sep  \\\n",
      "0      [Enjoying, a, beautiful, day, at, the, park!]   \n",
      "1           [Traffic, was, terrible, this, morning.]   \n",
      "2         [Just, finished, an, amazing, workout!, ðŸ’ª]   \n",
      "3  [Excited, about, the, upcoming, weekend, getaw...   \n",
      "4  [Trying, out, a, new, recipe, for, dinner, ton...   \n",
      "\n",
      "                                     Hashtags           Hashtags_sep  \\\n",
      "0   #Nature #Park                                   [#Nature, #Park]   \n",
      "1   #Traffic #Morning                           [#Traffic, #Morning]   \n",
      "2   #Fitness #Workout                           [#Fitness, #Workout]   \n",
      "3   #Travel #Adventure                         [#Travel, #Adventure]   \n",
      "4   #Cooking #Food                                 [#Cooking, #Food]   \n",
      "\n",
      "   Country_sep  \n",
      "0        [USA]  \n",
      "1     [Canada]  \n",
      "2        [USA]  \n",
      "3         [UK]  \n",
      "4  [Australia]  \n"
     ]
    }
   ],
   "source": [
    "# Split the content of 'Text' and 'Hashtags' columns using space and save them to new columns\n",
    "df['text_sep'] = df['Text'].fillna('').str.split(' ').apply(lambda x: [word for word in x if word.strip()])\n",
    "df['Hashtags_sep'] = df['Hashtags'].fillna('').str.split(' ').apply(lambda x: [word for word in x if word.strip()])\n",
    "df['Country_sep'] = df['Country'].fillna('').str.split(' ').apply(lambda x: [word for word in x if word.strip()])\n",
    "\n",
    "# Display the cleaned-up DataFrame to verify the changes\n",
    "print(df[['Text', 'text_sep', 'Hashtags', 'Hashtags_sep', 'Country_sep']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output to directory\n",
    "\n",
    "df.to_csv('data_prep.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing data for wordcloud\n",
    "df['text_sep'] = df['text_sep'].astype(str)\n",
    "\n",
    "# Split each row into individual elements, flatten the list, and join into a single string\n",
    "text = ' '.join([item for sublist in df['text_sep'].str.split(', ') for item in sublist])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install stop-words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stop_words import get_stop_words\n",
    "\n",
    "stop_words = get_stop_words('en')\n",
    "stop_words = get_stop_words('english')\n",
    "\n",
    "from stop_words import safe_get_stop_words\n",
    "\n",
    "stop_words = safe_get_stop_words('unsupported language')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83329"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "# Fill NaN values with empty strings to prevent issues\n",
    "df['text_sep'] = df['text_sep'].fillna('')\n",
    "\n",
    "# Ensure all elements are strings\n",
    "df['text_sep'] = df['text_sep'].astype(str)\n",
    "\n",
    "# Split each row into individual elements, flatten the list, and join into a single string\n",
    "text = ' '.join([item for sublist in df['text_sep'].str.split(', ') for item in sublist])\n",
    "\n",
    "# Remove stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_text = ' '.join([word for word in text.split() if word.lower() not in stop_words])\n",
    "\n",
    "\n",
    "len(filtered_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame from the filtered text\n",
    "output_df = pd.DataFrame({'combined_text': [filtered_text]})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "output_df.to_csv('wordcloud_filtered.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame from the combined text\n",
    "output_df = pd.DataFrame({'combined_text': [text]})  # Create a DataFrame with a single column\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "output_df.to_csv('wordcloud.csv', index=False)  # index=False prevents writing row indices"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
